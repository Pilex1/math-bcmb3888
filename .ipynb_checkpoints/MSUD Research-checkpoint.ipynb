{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3f44d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from networkx.algorithms import community\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "from networkx.algorithms.community import k_clique_communities\n",
    "from community import community_louvain\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dc1af0-4515-4d8e-af7a-7ca06bc1b65d",
   "metadata": {},
   "source": [
    "Load proteins and remove the 4932 prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deb4bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "G0 = nx.read_weighted_edgelist(\"4932.protein.links.v11.5.txt\",comments=\"#\",nodetype=str)\n",
    "print(f\"number of nodes in original dataset: \", len(G0.nodes))\n",
    "\n",
    "#removing the prefix in proteins\n",
    "map_dic = {}\n",
    "\n",
    "for node in G0.nodes() :\n",
    "    map_dic[node] = node[5:]\n",
    "   \n",
    "G = nx.relabel_nodes(G0, map_dic)\n",
    "\n",
    "# remove essential proteins\n",
    "essential_proteins = pd.read_csv(\"yeast essential proteins.csv\", header=None)[1]\n",
    "print()\n",
    "print(essential_proteins)\n",
    "G.remove_nodes_from(essential_proteins)\n",
    "print(f\"number of nodes after removing essential proteins: \", len(G.nodes))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b30b8b6-9a96-4d92-a7c9-adce589eb6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of edges in original dataset\", len(G.edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d7ce30-4910-47f8-ae82-d7833cee0742",
   "metadata": {},
   "source": [
    "Remove edges below a fixed score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c437ce-e369-49c9-85fd-f6c3acc79dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete those edges with a combined score of <= threshold_score (small confidence)\n",
    "threshold_score = 500\n",
    "for edge in G.edges: \n",
    "    weight = list(G.get_edge_data(edge[0],edge[1]).values())\n",
    "    if(weight[0] <= threshold_score):\n",
    "        G.remove_edge(edge[0],edge[1])\n",
    "print(\"Number of edges after filtering over low score\", len(G.edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6ff27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "partLouvain = community_louvain.best_partition(G)\n",
    "number_of_communities = max(partLouvain.values())+1 #We add one because the indexing starts at 0.\n",
    "print('# of partitions for Louvain modularity =',number_of_communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb79513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's construct a dictionary object called 'communities'. The keys will be the community labels and the values \n",
    "# will be a list of nodes in that community. The more experienced python users among you will probably see an \n",
    "# easier/faster way to do this.\n",
    "\n",
    "communities = {} #empty dictionary\n",
    "for i in range(number_of_communities):\n",
    "    communities[i] = [] #create an empty list for each community\n",
    "\n",
    "for name, community in partLouvain.items():\n",
    "    communities[community].append(name) #go through the computed partition and add each node to the appropriate list\n",
    "    \n",
    "\n",
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX would be. \n",
    "# In your own investigations you can decide what is more useful.\n",
    "\n",
    "#Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in communities:\n",
    "    print('The size of community #', list(communities.keys())[k], 'is ',len(communities[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5030501c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# partLouvain is a dict where the keys are the node names (i.e. protein names) and values are the index of the community that the protein is part of\n",
    "\n",
    "protein_interest = set(['YER178W', 'YBR221C', 'YNL071W', 'YOR090C', 'YFL018C', 'YIL042C', 'YGL059W'])\n",
    "communities_interest = set()\n",
    "\n",
    "for p in protein_interest:\n",
    "    print(f\"protein {p} in community {partLouvain[p]}\")\n",
    "    communities_interest.add(partLouvain[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579dd71a-c7aa-4282-8ed9-f5a0992be188",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc5e9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add proteins of interest in the list below\n",
    "protein_interest = set(['YER178W', 'YBR221C', 'YNL071W', 'YOR090C', 'YFL018C', 'YIL042C', 'YGL059W'])\n",
    "degree_dic = {}\n",
    "\n",
    "for p in protein_interest:\n",
    "    degree_dic[p] = float(G.degree(p))\n",
    "    \n",
    "print(\"degree of each protein\")\n",
    "dict(sorted(degree_dic.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08871060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal make sure that community 1 and 4 are connecting\n",
    "# define the clusters as separate graphs\n",
    "\n",
    "#subgraph dict with community label as key and subgraph as value\n",
    "essential_proteins_cluster = {}\n",
    "\n",
    "for key in communities.keys():\n",
    "    essential_proteins_cluster[key] = G.subgraph(communities[key])\n",
    "\n",
    "layout_PPI = nx.spring_layout(G,k=1/np.sqrt(len(G)))\n",
    "\n",
    "for i in tqdm(range(len(essential_proteins_cluster))):\n",
    "    nx.draw(essential_proteins_cluster[i], pos=layout_PPI, node_color='red' if i in communities_interest else 'black')\n",
    "    \n",
    "    \n",
    "# nx.draw(essential_proteins_cluster[1],pos=layout_PPI,node_color='red')\n",
    "# nx.draw(essential_proteins_cluster[4],pos=layout_PPI,node_color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc404111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#edges dict with community label as key and (0,1) for edge/no-edge as value\n",
    "edges = {}\n",
    "for i in range(number_of_communities-1):\n",
    "    for j in range(i+1,number_of_communities):\n",
    "        edges[str(i)+str(j)] = 0\n",
    "\n",
    "for i in range(number_of_communities-1):\n",
    "    for node in essential_proteins_cluster[i].nodes():\n",
    "        for neighbor in G.neighbors(node):\n",
    "            for j in range(i+1,number_of_communities):\n",
    "                if neighbor in communities[j]:\n",
    "                    edges[str(i)+str(j)] += 1\n",
    "\n",
    "# print(edges) # convention: 'ij' denotes the edge between node(=community) i and node(=community) j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60966b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find the communities which have links to the community of the target community\n",
    "def get_connected_communities(community_index):\n",
    "\n",
    "    neighbor_community = []\n",
    "    for i in range(number_of_communities):\n",
    "        if i < target_community:\n",
    "            if edges[str(i)+str(target_community)] != 0:\n",
    "                neighbor_community.append(i)\n",
    "        if i > target_community:\n",
    "            if edges[str(target_community)+str(i)] != 0:\n",
    "                neighbor_community.append(i)\n",
    "    return neighbor_community\n",
    "\n",
    "\n",
    "target_community = partLouvain['YOR090C']\n",
    "print(f\"community {target_community} is connected to communities {get_connected_communities(target_community)}\")\n",
    "\n",
    "target_community = partLouvain['YER178W']\n",
    "print(f\"community {target_community} is connected to communities {get_connected_communities(target_community)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0763607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G.has_edge('YER178W','YOR090C'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3d4a22-5814-4415-967c-a422691e5c35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
