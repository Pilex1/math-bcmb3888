{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "668e3194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from networkx.algorithms import community\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "from networkx.algorithms.community import k_clique_communities\n",
    "from community import community_louvain\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07b67df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes in original dataset:  6394\n",
      "\n",
      "0         YAL001C\n",
      "1         YAL003W\n",
      "2         YAL012W\n",
      "3         YAL025C\n",
      "4         YAL032C\n",
      "          ...    \n",
      "1308    YKL138C-A\n",
      "1309    YNL138W-A\n",
      "1310    YNL024C-A\n",
      "1311    YHR199C-A\n",
      "1312    YIL102C-A\n",
      "Name: 1, Length: 1313, dtype: object\n",
      "number of nodes after removing essential proteins:  5098\n"
     ]
    }
   ],
   "source": [
    "G0 = nx.read_weighted_edgelist(\"4932.protein.links.v11.5.txt\",comments=\"#\",nodetype=str)\n",
    "print(f\"number of nodes in original dataset: \", len(G0.nodes))\n",
    "\n",
    "#removing the prefix in proteins\n",
    "map_dic = {}\n",
    "\n",
    "for node in G0.nodes() :\n",
    "    map_dic[node] = node[5:]\n",
    "   \n",
    "G = nx.relabel_nodes(G0, map_dic)\n",
    "\n",
    "# remove essential proteins\n",
    "essential_proteins = pd.read_csv(\"yeast essential proteins.csv\", header=None)[1]\n",
    "print()\n",
    "print(essential_proteins)\n",
    "G.remove_nodes_from(essential_proteins)\n",
    "print(f\"number of nodes after removing essential proteins: \", len(G.nodes))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44f08179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of partitions for Louvain modularity = 41\n"
     ]
    }
   ],
   "source": [
    "partLouvain = community_louvain.best_partition(G)\n",
    "number_of_communities = max(partLouvain.values())+1 #We add one because the indexing starts at 0.\n",
    "print('# of partitions for Louvain modularity =',number_of_communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6a0dff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of community # 0 is  345\n",
      "The size of community # 1 is  1027\n",
      "The size of community # 2 is  1080\n",
      "The size of community # 3 is  829\n",
      "The size of community # 4 is  767\n",
      "The size of community # 5 is  542\n",
      "The size of community # 6 is  474\n",
      "The size of community # 7 is  1\n",
      "The size of community # 8 is  1\n",
      "The size of community # 9 is  1\n",
      "The size of community # 10 is  1\n",
      "The size of community # 11 is  1\n",
      "The size of community # 12 is  1\n",
      "The size of community # 13 is  1\n",
      "The size of community # 14 is  1\n",
      "The size of community # 15 is  1\n",
      "The size of community # 16 is  1\n",
      "The size of community # 17 is  1\n",
      "The size of community # 18 is  1\n",
      "The size of community # 19 is  1\n",
      "The size of community # 20 is  1\n",
      "The size of community # 21 is  1\n",
      "The size of community # 22 is  1\n",
      "The size of community # 23 is  1\n",
      "The size of community # 24 is  1\n",
      "The size of community # 25 is  1\n",
      "The size of community # 26 is  1\n",
      "The size of community # 27 is  1\n",
      "The size of community # 28 is  1\n",
      "The size of community # 29 is  1\n",
      "The size of community # 30 is  1\n",
      "The size of community # 31 is  1\n",
      "The size of community # 32 is  1\n",
      "The size of community # 33 is  1\n",
      "The size of community # 34 is  1\n",
      "The size of community # 35 is  1\n",
      "The size of community # 36 is  1\n",
      "The size of community # 37 is  1\n",
      "The size of community # 38 is  1\n",
      "The size of community # 39 is  1\n",
      "The size of community # 40 is  1\n"
     ]
    }
   ],
   "source": [
    "# Let's construct a dictionary object called 'communities'. The keys will be the community labels and the values \n",
    "# will be a list of nodes in that community. The more experienced python users among you will probably see an \n",
    "# easier/faster way to do this.\n",
    "\n",
    "communities = {} #empty dictionary\n",
    "for i in range(number_of_communities):\n",
    "    communities[i] = [] #create an empty list for each community\n",
    "\n",
    "for name, community in partLouvain.items():\n",
    "    communities[community].append(name) #go through the computed partition and add each node to the appropriate list\n",
    "    \n",
    "\n",
    "# The dictionary we have constructed is similar to what the output of the Louvain algorithm in NetworkX would be. \n",
    "# In your own investigations you can decide what is more useful.\n",
    "\n",
    "#Now let's find out how big each community is. You could accomplish this in the following way:\n",
    "for k in communities:\n",
    "    print('The size of community #', list(communities.keys())[k], 'is ',len(communities[k]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f215e6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protein YIL042C in community 4\n",
      "protein YGL059W in community 4\n",
      "protein YNL071W in community 1\n",
      "protein YER178W in community 1\n",
      "protein YBR221C in community 1\n",
      "protein YOR090C in community 4\n",
      "protein YFL018C in community 1\n"
     ]
    }
   ],
   "source": [
    "# partLouvain is a dict where the keys are the node names (i.e. protein names) and values are the index of the community that the protein is part of\n",
    "\n",
    "protein_interest = set(['YER178W', 'YBR221C', 'YNL071W', 'YOR090C', 'YFL018C', 'YIL042C', 'YGL059W'])\n",
    "for p in protein_interest:\n",
    "    print(f\"protein {p} in community {partLouvain[p]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5cbdff8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree of each protein\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'YIL042C': 266.0,\n",
       " 'YGL059W': 272.0,\n",
       " 'YOR090C': 317.0,\n",
       " 'YNL071W': 491.0,\n",
       " 'YBR221C': 580.0,\n",
       " 'YFL018C': 582.0,\n",
       " 'YER178W': 596.0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add proteins of interest in the list below\n",
    "protein_interest = set(['YER178W', 'YBR221C', 'YNL071W', 'YOR090C', 'YFL018C', 'YIL042C', 'YGL059W'])\n",
    "degree_dic = {}\n",
    "\n",
    "for p in protein_interest:\n",
    "    degree_dic[p] = float(G.degree(p))\n",
    "    \n",
    "print(\"degree of each protein\")\n",
    "dict(sorted(degree_dic.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596d540f-43e0-488f-a238-a388636cf557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
