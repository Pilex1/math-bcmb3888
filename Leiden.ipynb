{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from networkx.algorithms import community\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "from networkx.algorithms.community import k_clique_communities\n",
    "from community import community_louvain\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes in original dataset:  6394\n",
      "\n",
      "0         YAL001C\n",
      "1         YAL003W\n",
      "2         YAL012W\n",
      "3         YAL025C\n",
      "4         YAL032C\n",
      "          ...    \n",
      "1308    YKL138C-A\n",
      "1309    YNL138W-A\n",
      "1310    YNL024C-A\n",
      "1311    YHR199C-A\n",
      "1312    YIL102C-A\n",
      "Name: 1, Length: 1313, dtype: object\n",
      "number of nodes after removing essential proteins:  6324\n"
     ]
    }
   ],
   "source": [
    "G0 = nx.read_weighted_edgelist(\"4932.protein.links.v11.5.txt\",comments=\"#\",nodetype=str)\n",
    "print(f\"number of nodes in original dataset: \", len(G0.nodes))\n",
    "\n",
    "#removing the prefix in proteins\n",
    "protein_info = pd.read_csv(\"Protein_info.txt\", sep='\\t')\n",
    "map_dic = protein_info.set_index('#string_protein_id').to_dict()['preferred_name']\n",
    "   \n",
    "G = nx.relabel_nodes(G0, map_dic)\n",
    "\n",
    "# remove essential proteins\n",
    "essential_proteins = pd.read_csv(\"yeast essential proteins.csv\", header=None)[1]\n",
    "print()\n",
    "print(essential_proteins)\n",
    "G.remove_nodes_from(essential_proteins)\n",
    "print(f\"number of nodes after removing essential proteins: \", len(G.nodes))  \n",
    "\n",
    "# delete those edges with a combined score of <= threshold_score (small confidence)\n",
    "threshold_score = 500\n",
    "for edge in G.edges: \n",
    "    weight = list(G.get_edge_data(edge[0],edge[1]).values())\n",
    "    if(weight[0] <= threshold_score):\n",
    "        G.remove_edge(edge[0],edge[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of partitions for Louvain modularity = 308\n"
     ]
    }
   ],
   "source": [
    "partLouvain = community_louvain.best_partition(G)\n",
    "number_of_communities = max(partLouvain.values())+1 #We add one because the indexing starts at 0.\n",
    "print('# of partitions for Louvain modularity =',number_of_communities)\n",
    "communities = {} #empty dictionary\n",
    "for i in range(number_of_communities):\n",
    "    communities[i] = [] #create an empty list for each community\n",
    "\n",
    "for name, community in partLouvain.items():\n",
    "    communities[community].append(name) #go through the computed partition and add each node to the appropriate list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protein PDA1 in community 9\n",
      "protein PDB1 in community 9\n",
      "protein LAT1 in community 9\n",
      "protein LPD1 in community 9\n",
      "protein PKP1 in community 6\n",
      "protein PKP2 in community 6\n",
      "protein PTC5 in community 6\n"
     ]
    }
   ],
   "source": [
    "protein_interest = ['PDA1', 'PDB1', 'LAT1', 'LPD1', 'PKP1', 'PKP2', 'PTC5']\n",
    "communities_interest = set()\n",
    "\n",
    "for p in protein_interest:\n",
    "    print(f\"protein {p} in community {partLouvain[p]}\")\n",
    "    communities_interest.add(partLouvain[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_enz = G.subgraph(communities[list(communities_interest)[1]]) #subgraph of community with phosphatase and kinase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDH regulators in same community 86 out of 100 times.\n",
      "Common proteins in all the times the 3 regulators were in the same community: 0\n"
     ]
    }
   ],
   "source": [
    "from cdlib.algorithms import leiden\n",
    "# Apply Leiden on the PDH regulators 100 times\n",
    "p_reg = protein_interest[4:]\n",
    "in_same_comm = 0\n",
    "prev_run = set()\n",
    "for i in range(0, 100):\n",
    "    communities = leiden(G_enz)\n",
    "    idx = 0\n",
    "    for c in communities.communities:\n",
    "        counter = 0\n",
    "        for p in p_reg:\n",
    "            if p in c:\n",
    "                counter += 1\n",
    "        if counter == 3:\n",
    "            if prev_run == {}:\n",
    "                prev_run = prev_run | set(c)\n",
    "            else:\n",
    "                prev_run = prev_run & set(c)\n",
    "            in_same_comm += 1\n",
    "        idx += 1\n",
    "\n",
    "print(\"PDH regulators in same community {} out of 100 times.\".format(in_same_comm))\n",
    "print(\"Common proteins in all the times the 3 regulators were in the same community: {}\".format(len(prev_run)))\n",
    "# Conclusion: Regulators were in the same community around (50-95)/100 times. However, there were no common\n",
    "# proteins found in all of these runs. Hence, no new information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
